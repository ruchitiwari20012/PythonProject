{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "df=pd.read_csv('adult.data.csv')\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Their is no null value present in the dataset from the above code we have observed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "from the datatype code aboserved that i have to change the datatpye of most of the columns so i will apply the \n",
    "label encoder  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "le=LabelEncoder()\n",
    "df[ ' State-gov']=le.fit_transform(df[ ' State-gov'])\n",
    "df[' Bachelors']=le.fit_transform(df[' Bachelors'])\n",
    "df[' Never-married']=le.fit_transform(df[' Never-married'])\n",
    "df[' Adm-clerical']=le.fit_transform(df[' Adm-clerical'])\n",
    "df[' Not-in-family']=le.fit_transform(df[' Not-in-family'])\n",
    "df[' White']=le.fit_transform(df[' White'])\n",
    "df[' Male']=le.fit_transform(df[' Male'])\n",
    "df[' United-States']=le.fit_transform(df[' United-States'])\n",
    "df[' <=50K']=le.fit_transform(df[' <=50K'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "from the above statement it shows that datatype is changed and now we can move ahead "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.heatmap(df.isnull())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfcor=df.corr()\n",
    "dfcor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.heatmap(dfcor)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "from the graph it shows that their is positive correlation between the columns Bachelors and the 13 \n",
    "the <=50k columns have a little bit positive relation with the Male ,2174,0 ,13,39and 40 columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.skew()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From the above it shows that their is skewness present in the data no we will deal with it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Treating using log\n",
    "import numpy as np\n",
    "for col in df.columns:\n",
    "    if df.skew().loc[col]>0.55:\n",
    "        df[col]=np.log1p(df[col])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.skew()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now skewness was removed from the dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lets check the outliers presentin the dataset or not "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[' State-gov'].plot.box()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[' Bachelors'].plot.box()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Their is present outlier we will aplly zscore for it "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Lets Check wherther their outlier are present in the dataset or not \n",
    "from scipy.stats import zscore\n",
    "zscore=abs(zscore(df))\n",
    "print(df.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_final=df.loc[(zscore<3).all(axis=1)]\n",
    "print(df_final.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From the above 6620 rows got removed as an outliers "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Lets check pairplot using seaborn library\n",
    "#import seaborn as sns\n",
    "#sns.pairplot(df_final)\n",
    "#plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#I am not running this code bcoz it take lot of time to execute in my system"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Separating  the target and input variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "sc=StandardScaler()\n",
    "x=sc.fit_transform(df_final)\n",
    "x=pd.DataFrame(x,columns=df_final.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x.drop(' 0', axis = 1, inplace = True) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x=df_final.iloc[:,0:-1]\n",
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y=df_final.iloc[:,-1]\n",
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y=df_final.iloc[:,-1].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split,cross_val_score\n",
    "x_train,x_test,y_train,y_test=train_test_split(x,y,test_size=0.3,random_state=9,stratify=y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(x_train.shape,x_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(y_train.shape,y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import cross_val_predict\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.metrics import confusion_matrix\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_absolute_error\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.metrics import r2_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "def maxr2_score(regr,x,y):\n",
    "    max_r_score=0\n",
    "    for r_state in range(42,100):\n",
    "        x_train, x_test, y_train, y_test = train_test_split(x, y,random_state = r_state,test_size=0.20)\n",
    "        regr.fit(x_train,y_train)\n",
    "        y_pred = regr.predict(x_test)\n",
    "        r2_scr=r2_score(y_test,y_pred)\n",
    "        print(\"r2 score corresponding to \",r_state,\" is \",r2_scr)\n",
    "        if r2_scr>max_r_score:\n",
    "            max_r_score=r2_scr\n",
    "            final_r_state=r_state\n",
    "    print(\"max r2 score corressponding to \",final_r_state,\" is \",max_r_score)\n",
    "    return final_r_state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Lets use Linear regression and check max r2 score corressponding to different random state\n",
    "from sklearn.linear_model import LinearRegression\n",
    "lreg=LinearRegression()\n",
    "r_state=maxr2_score(lreg,x,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Lets use grid_search to find optimal value of n_neigbors for KNN model\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "neighbors={\"n_neighbors\":range(1,30)}\n",
    "knr=KNeighborsRegressor()\n",
    "gknr = GridSearchCV(knr,neighbors, cv=5)\n",
    "gknr.fit(x,y)\n",
    "gknr.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Lets use KNN regression and check max r2 score corresponding to different random states\n",
    "knr=KNeighborsRegressor(n_neighbors=19)\n",
    "r_state=maxr2_score(knr,x,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Lets check the mean r2 score of both LinearRegression model and knn regression\n",
    "from sklearn.model_selection import cross_val_score\n",
    "print(\"Mean r2 score for Linear Regression :\",cross_val_score(lreg,x,y,cv=5,scoring=\"r2\").mean())\n",
    "print(\"standard deviation in r2 score for Linear Regression:\",cross_val_score(lreg,x,y,cv=5,scoring=\"r2\").std())\n",
    "print()\n",
    "print(\"Mean r2 score for KNN Regression:\",cross_val_score(knr,x,y,cv=5,scoring=\"r2\").mean())\n",
    "print(\"standard deviation in r2 score for KNN Regression: \",cross_val_score(knr,x,y,cv=5,scoring=\"r2\").std())\n",
    "#Based on below output Linear Regression is performing well"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Lets check laso Regression and find best value of alpha\n",
    "from sklearn.linear_model import Lasso\n",
    "lsreg=Lasso()\n",
    "parameters={\"alpha\":[0.001,0.01,0.1,1]}\n",
    "clf = GridSearchCV(lsreg, parameters, cv=10)\n",
    "clf.fit(x,y)\n",
    "clf.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Lets check max_r2 score whenwe use lasso\n",
    "lsreg=Lasso(alpha=0.001)\n",
    "r_stat=maxr2_score(lsreg,x,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Lets use cross val score with lasso\n",
    "print(\"Mean r2_score for Lasso Regression: \",cross_val_score(lsreg,x,y,cv=5,scoring=\"r2\").mean())\n",
    "print(\"standard deviation in r2 score for Lasso Regression: \",cross_val_score(lsreg,x,y,cv=5,scoring=\"r2\").std())\n",
    "#Based on below output i can say lasso performed just like linear regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Now we will try to use gradient boosting technique\n",
    "#for getting best set of parameters we will use grid search\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "gbr=GradientBoostingRegressor()\n",
    "parameters={\"learning_rate\":[0.001,0.01,0.1,1],\"n_estimators\":[10,100,500,1000,]}\n",
    "clr = GridSearchCV(gbr, parameters, cv=5)\n",
    "clf.fit(x,y)\n",
    "clf.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Now we will use cross val score to check the mean r2 score and standard deviation\n",
    "gbr=GradientBoostingRegressor(learning_rate=0.001,n_estimators=500)\n",
    "print(\"Mean r2 score for gradiant boosting Regression: \",cross_val_score(gbr,x,y,cv=5,scoring=\"r2\").mean())\n",
    "print(\"standard deviation in r2 score for gradient boosting Regression: \",cross_val_score(gbr,x,y,cv=5,scoring=\"r2\").std())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Now lets use the ada boost regression algorithm\n",
    "from sklearn.ensemble import AdaBoostRegressor\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "ada_reg=AdaBoostRegressor()\n",
    "parameters={\"learning_rate\":[0.001,0.01,0.1,1],\"n_estimators\":[10,100,500,1000],\"base_estimator\":[lreg,lsreg,DecisionTreeRegressor()]}\n",
    "clf = GridSearchCV(ada_reg, parameters, cv=5)\n",
    "clf.fit(x,y)\n",
    "clf.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ada_reg=AdaBoostRegressor(base_estimator=lsreg,learning_rate=0.001,n_estimators=10)\n",
    "print(\"Mean r2 score for ada boosting Regression: \",cross_val_score(ada_reg,x,y,cv=5,scoring=\"r2\").mean())\n",
    "print(\"standard deviation in r2 score for ada boosting Regression: \",cross_val_score(ada_reg,x,y,cv=5,scoring=\"r2\").std())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Lets check maximum r2_score corresponding to this\n",
    "r_state=maxr2_score(ada_reg,x,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Till now we have observed that the score we are getting is very less\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, x_test, y_train, y_test = train_test_split(x, y,random_state = 88,test_size=0.20)\n",
    "lreg=LinearRegression()\n",
    "lreg.fit(x_train,y_train)\n",
    "y_pred=lreg.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Lets find the rmse and r2_score using sklearn,metrics \n",
    "import numpy as np\n",
    "from sklearn.metrics import r2_score\n",
    "from sklearn.metrics import mean_squared_error \n",
    "print(\"RMSE is: \",np.sqrt(mean_squared_error(y_test,y_pred)))\n",
    "print(\"r2_score is: \",r2_score(y_test,y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#from sklearn.externals import joblib\n",
    "\n",
    "#save the model as a pickel in a file\n",
    "joblib.dump(lreg, \"census_lreg.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
