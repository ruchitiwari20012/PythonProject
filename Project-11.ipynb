{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "df=pd.read_csv('Automobile Insurance claim amount.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Lets Check the null values\n",
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Their is no nul value present in the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Lets check the datatypes of the columns \n",
    "df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import sklearn\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_squared_error,mean_absolute_error\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.heatmap(df.isnull())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#1) The mean is more than the median(50th percentile in all columns). \n",
    "#2)Their is large difference in 75% and max in claim amount,Income,Monthly Premium Auto and the Total Claim Amount. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfcor=df.corr()\n",
    "dfcor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.heatmap(dfcor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#From the graph we observe that their is mostly negative correlation among the columns \n",
    "#Monthly Premium Auto and Total Claim Amount are little bit corrleated."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.columns "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.violinplot(x='Claim Amount',data=df)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#From the garph it represent that mostly claim amount was between the 500 to 1500"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.distplot(df['Claim Amount'],bins=20)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.barplot(x='Vehicle Class',y='Total Claim Amount',data=df)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#From this graph it clearly shows that Luxury car and the Luxury SUV have the highest number of total claim amount "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.catplot(x='Vehicle Class',y='Total Claim Amount',data=df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Again i am checking the datatype so that i their is any other datatype of string i will convert it into the other datatype\n",
    "df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# I am using the Label Encoder to change the datatype of the particular columns so that i can work futher \n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "le=LabelEncoder()\n",
    "df['Customer']=le.fit_transform(df['Customer'])\n",
    "df['Country']=le.fit_transform(df['Country'])\n",
    "df['State Code']=le.fit_transform(df['State Code'])\n",
    "df['State']=le.fit_transform(df['State'])\n",
    "df['Response']=le.fit_transform(df['Response'])\n",
    "df['Coverage']=le.fit_transform(df['Coverage'])\n",
    "df['Education']=le.fit_transform(df['Education'])\n",
    "df['Effective To Date']=le.fit_transform(df['Effective To Date'])\n",
    "df['EmploymentStatus']=le.fit_transform(df['EmploymentStatus'])\n",
    "df['Gender']=le.fit_transform(df['Gender'])\n",
    "df['Location Code']=le.fit_transform(df['Location Code'])\n",
    "df['Marital Status']=le.fit_transform(df['Marital Status'])\n",
    "df['Policy Type']=le.fit_transform(df['Policy Type'])\n",
    "df['Policy']=le.fit_transform(df['Policy'])\n",
    "df['Claim Reason']=le.fit_transform(df['Claim Reason'])\n",
    "df['Sales Channel']=le.fit_transform(df['Sales Channel'])\n",
    "df['Vehicle Class']=le.fit_transform(df['Vehicle Class'])\n",
    "df['Vehicle Size']=le.fit_transform(df['Vehicle Size'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.skew()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Treating using log\n",
    "import numpy as np\n",
    "for col in df.columns:\n",
    "    if df.skew().loc[col]>0.55:\n",
    "        df[col]=np.log1p(df[col])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.skew()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Total Claim Amount'].plot.box()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Vehicle Class'].plot.box()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Income'].plot.box()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "collist=df.columns.values\n",
    "ncol=26\n",
    "nrows=10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(ncol,5*ncol))\n",
    "for i in range(1,len(collist)):\n",
    "    plt.subplot(nrows,ncol,i+1)\n",
    "    sns.boxplot(df[collist[i]],color='green',orient='v')\n",
    "    plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Lets check for outliers\n",
    "from scipy.stats import zscore\n",
    "z_score=abs(zscore(df))\n",
    "print(df.shape)\n",
    "df_final=df.loc[(z_score<3).all(axis=1)]\n",
    "print(df_final.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I am not able to identify that after applying the zscore still i am getting the 0 value in row columns so i am \n",
    "working continue on the df dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.pairplot(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.hist(figsize=(26,26))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Now saperating the x and y for prediction the claim amount in the Automobile insurance dataset.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "sc=StandardScaler()\n",
    "x=sc.fit_transform(df)\n",
    "x=pd.DataFrame(x,columns=df.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x\n",
    "x.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y=df.iloc[:,-22]\n",
    "y.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "le=LabelEncoder()\n",
    "y=le.fit_transform(y)\n",
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_absolute_error\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.metrics import r2_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "def maxr2_score(regr,x,y):\n",
    "    max_r_score=0\n",
    "    for r_state in range(42,100):\n",
    "        x_train, x_test, y_train, y_test = train_test_split(x, y,random_state = r_state,test_size=0.20)\n",
    "        regr.fit(x_train,y_train)\n",
    "        y_pred = regr.predict(x_test)\n",
    "        r2_scr=r2_score(y_test,y_pred)\n",
    "        print(\"r2 score corresponding to \",r_state,\" is \",r2_scr)\n",
    "        if r2_scr>max_r_score:\n",
    "            max_r_score=r2_scr\n",
    "            final_r_state=r_state\n",
    "    print(\"max r2 score corressponding to \",final_r_state,\" is \",max_r_score)\n",
    "    return final_r_state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Lets use Linear regression and check max r2 score corressponding to different random state\n",
    "from sklearn.linear_model import LinearRegression\n",
    "lreg=LinearRegression()\n",
    "r_state=maxr2_score(lreg,x,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Lets use grid_search to find optimal value of n_neigbors for KNN model\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "neighbors={\"n_neighbors\":range(1,30)}\n",
    "knr=KNeighborsRegressor()\n",
    "gknr = GridSearchCV(knr,neighbors, cv=5)\n",
    "gknr.fit(x,y)\n",
    "gknr.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Lets use KNN regression and check max r2 score corresponding to different random states\n",
    "knr=KNeighborsRegressor(n_neighbors=11)\n",
    "r_state=maxr2_score(knr,x,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Lets check the mean r2 score of both LinearRegression model and knn regression\n",
    "from sklearn.model_selection import cross_val_score\n",
    "print(\"Mean r2 score for Linear Regression :\",cross_val_score(lreg,x,y,cv=5,scoring=\"r2\").mean())\n",
    "print(\"standard deviation in r2 score for Linear Regression:\",cross_val_score(lreg,x,y,cv=5,scoring=\"r2\").std())\n",
    "print()\n",
    "print(\"Mean r2 score for KNN Regression:\",cross_val_score(knr,x,y,cv=5,scoring=\"r2\").mean())\n",
    "print(\"standard deviation in r2 score for KNN Regression: \",cross_val_score(knr,x,y,cv=5,scoring=\"r2\").std())\n",
    "#Based on below output Linear Regression is performing well"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Lets check laso Regression and find best value of alpha\n",
    "from sklearn.linear_model import Lasso\n",
    "lsreg=Lasso()\n",
    "parameters={\"alpha\":[0.001,0.01,0.1,1]}\n",
    "clf = GridSearchCV(lsreg, parameters, cv=5)\n",
    "clf.fit(x,y)\n",
    "clf.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Lets check max_r2 score whenwe use lasso\n",
    "lsreg=Lasso(alpha=1)\n",
    "r_stat=maxr2_score(lsreg,x,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Lets use cross val score with lasso\n",
    "print(\"Mean r2_score for Lasso Regression: \",cross_val_score(lsreg,x,y,cv=5,scoring=\"r2\").mean())\n",
    "print(\"standard deviation in r2 score for Lasso Regression: \",cross_val_score(lsreg,x,y,cv=5,scoring=\"r2\").std())\n",
    "#Based on below output i can say lasso performed just like linear regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Now we will try to use gradient boosting technique\n",
    "#for getting best set of parameters we will use grid search\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "gbr=GradientBoostingRegressor()\n",
    "parameters={\"learning_rate\":[0.001,0.01,0.1,1],\"n_estimators\":[10,100,500,1000,]}\n",
    "clr = GridSearchCV(gbr, parameters, cv=5)\n",
    "clf.fit(x,y)\n",
    "clf.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Now we will use cross val score to check the mean r2 score and standard deviation\n",
    "gbr=GradientBoostingRegressor(learning_rate=1,n_estimators=500)\n",
    "print(\"Mean r2 score for gradiant boosting Regression: \",cross_val_score(gbr,x,y,cv=5,scoring=\"r2\").mean())\n",
    "print(\"standard deviation in r2 score for gradient boosting Regression: \",cross_val_score(gbr,x,y,cv=5,scoring=\"r2\").std())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Lets check maximum r2_score corresponding to this\n",
    "r_state=maxr2_score(gbr,x,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Till now we have observed that gradiant boosting regression is working well\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, x_test, y_train, y_test = train_test_split(x, y,random_state = 85,test_size=0.20)\n",
    "gbr=GradientBoostingRegressor()\n",
    "gbr.fit(x_train,y_train)\n",
    "y_pred=gbr.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Lets find the rmse and r2_score using sklearn,metrics \n",
    "import numpy as np\n",
    "from sklearn.metrics import r2_score\n",
    "from sklearn.metrics import mean_squared_error \n",
    "print(\"RMSE is: \",np.sqrt(mean_squared_error(y_test,y_pred)))\n",
    "print(\"r2_score is: \",r2_score(y_test,y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.externals import joblib\n",
    "\n",
    "#save the model as a pickel in a file\n",
    "joblib.dump(gbr, \"Automobile_gbr.pkl\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You will see that in LinearRegression r2 score of 72 is 0.95\n",
    "In KNeighborsRegression r2 score of 82 is 0.83\n",
    "In Lasso r2 score of 72 is 0.95\n",
    "In GradientBoostingRegressor r2 score of 85 is 0.99 \n",
    "So best among is GradientBoostingRegressor i have save that "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Conclusion : In this dataset firstly i look the data since i have to predict the claim amount in the Automobile insurance dataset so I take it as a Y variable and rest column was taken as a X before spliting the dataset i check the datatype and change the datatype of the columns and see the correlation , null values , description, skewness and pairplot i check the outlier also.Than I split the data into x and y and apply the standard scaler in x and in y the label encoder.\n",
    "\n",
    "You will see that in LinearRegression r2 score of 72 is 0.95\n",
    "In KNeighborsRegression r2 score of 82 is 0.83\n",
    "In Lasso r2 score of 72 is 0.95\n",
    "In GradientBoostingRegressor r2 score of 85 is 0.99 \n",
    "So best among is GradientBoostingRegressor i have save that "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
